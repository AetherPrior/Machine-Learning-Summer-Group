{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "Logistic Regression is a method when the variable to be determined(the dependent variable) is categorical. It might be helpful to think of it as a probabilistic classification model. It is used to assign observations to a discrete set of classes. Logistic regression transforms its output using the logistic sigmoid function to return a probability value which can then be mapped to two or more discrete classes. For example, To predict\n",
    "\n",
    "1. If an email is spam(1) or not(0)\n",
    "2. If a given image is of a cat(1) or not(0)\n",
    "3. If a tumor is malignant(1) or not(0)\n",
    "\n",
    "> Although multiclass classification is possible as well (ex: Movie Rating from 1 to 5, or food preference between vegan, veg or non-veg) it is beyond the scope of this course. Feel free to read up about it and ask us about any doubts regarding the same\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Comparison To Linear Regression\n",
    "\n",
    "Where Linear Regression is used to predict continuous numerical values, Logistic Regression's predictions are discrete (only certain values or categories are allowed). It represents the probability of the sample belonging to a particular category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Binary Logistic Regression\n",
    "Say you are given data on student exam results, and your goal is to predict whether a student will pass or fail based on the number of hours slept, and the hours studied. In this case we have,\n",
    "1. Features: \n",
    " - Hours Slept\n",
    " - Hours Studied\n",
    "2. Classes:\n",
    " - Pass(1)\n",
    " - Fail(0)\n",
    " \n",
    "Ex:\n",
    "\n",
    "Studied (hrs) | Slept (hrs) | Result |\n",
    "--------------| ----------- | -------|\n",
    "4.85 | 9.63 | 1\n",
    "8.62 | 3.23 | 0\n",
    "5.43 | 8.23 | 1\n",
    "st | sl | ?\n",
    "\n",
    " \n",
    "So in this case we need to calculate that given a student has slept for $ sl $ hours and studied for $ st $ for a test what is the probability that he will pass, and what is the probability that he will fail. More Formally,\n",
    "\n",
    "$$ P(result = Pass | Slept = sl, Studied = st) $$ and\n",
    "$$ P(result = Fail | Slept = sl, Studied = st) $$\n",
    "\n",
    "Or, abstracting into variables, \n",
    "\n",
    "$$ p = P(Y = 1 | x_1, x_2, ..., x_n) $$ \n",
    "$$ q = P(Y = 0 | x_1, x_2, ..., x_n) $$\n",
    "\n",
    "where, \n",
    "> Y is the class that the sample data belongs to\n",
    "> $x_i$ are the various features of the data\n",
    "\n",
    "Now, notice that since $p$ and $q$ are the only possible classes and represent probabilities,\n",
    "\n",
    "$$ p + q = 1 $$ \n",
    "\n",
    "and calculating any one of them is sufficient to find the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 The Linear Function\n",
    "\n",
    "The first Step in creating a Logistic regression Model is similar to a linear regression Model. We need to take a linear combination of all the features, and a constant amount to it. In Linear Regression you saw them called as parameters, labeled as $\\theta$:\n",
    "\n",
    "$$ h_\\theta(x) = \\theta_0 + \\theta_1x_1 + \\theta_2x_2 + ... + \\theta_nx_n $$\n",
    "or, in vectorized form:\n",
    "$$ h_\\theta(x) = x \\cdot \\theta $$.\n",
    "\n",
    "From here on we will be using the notation more commonly used in Neural Network Architectures. \n",
    "The $\\theta_0$ term is called the bias, and the parameters $\\theta_1, \\theta_2, ..., \\theta_n $ the weights.\n",
    "\n",
    "The Output of the linear Function is now represented as: \n",
    "\n",
    "$$ z(x) = w_1x_1 + w_2x_2 + ... + w_nx_n + b $$\n",
    "> where:\n",
    "1. $z$ is a scalar,\n",
    "2. $w_i$ are the scalar weights\n",
    "3. $b$ is the sclar bias\n",
    "\n",
    "Now, this can also be written as a matrix product as follows:\n",
    "\n",
    "$$ z = w \\cdot x + b $$\n",
    "\n",
    "> where,\n",
    "1. $x$ = feature vector of shape $(n_x, 1) = (x_1, x_2, ..., x_n)$ stacked in a column\n",
    "2. $w$ = weight matrix of shape $ (1, n_x) = [[w_1], [w_2], ..., [w_3]]$ stacked in a row\n",
    "3. $b$ = scalar bias\n",
    "\n",
    "And as always, a linear function is unbounded and so, \n",
    "$$ z \\in (-\\infty, \\infty) $$\n",
    "\n",
    "> If at any point you are confused with notation, check the Notation Section at the bottom. There is a quick reference there, and if the doubt still persists PM one of us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Activation Functions: The Sigmoid Function\n",
    "As you already saw in Linear Regression, the function $z = w \\cdot x + b$ is unbounded. However, since we are calculating the probability, we need to scale the value of $Z$ (obtained from Linear Regression) to the range $[0, 1]$. To achieve this we use the Sigmoid function.\n",
    "\n",
    "The sigmoid, or the logistic Function is a special function which maps its input to values between 0 and 1. It is an S shaped curve defined by the following equation:\n",
    " \n",
    "$$ S(z) = \\sigma(z) = \\frac{1}{1 + e^{-z}} $$\n",
    " \n",
    "> Notes:\n",
    "> 1. $S(Z) \\in [0, 1] $\n",
    "> 2. z = Input to your function (The prediction of the linear regression model, ie: $wx + b$\n",
    "\n",
    "<img src=\"https://ml-cheatsheet.readthedocs.io/en/latest/_images/sigmoid.png\">\n",
    "\n",
    "> Try to find other functions with similar properties, or similar shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWrite the code for logistic Regression\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Write the code for logistic Regression in numpy\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Decision Boundary\n",
    "Our current Prediction returns a probability between 0 and 1. In order to map this value to a discrete class, we select a threshold value or the tipping point. All values aobe this tipping point are classified into \"Class 1\", and all below to \"Class 2\".\n",
    "\n",
    "For example if our threshold value was 0.5,\n",
    "\n",
    "$$ p \\ge 0.5 \\implies class = 1 $$\n",
    "$$ p \\lt 0.5 \\implies class = 2 $$\n",
    "\n",
    "<img src=\"https://ml-cheatsheet.readthedocs.io/en/latest/_images/logistic_regression_sigmoid_w_threshold.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Making Predictions\n",
    "\n",
    "Using our knowledge of sigmoid functions and decision boundaries, we can now write a prediction function. A prediction function in logistic regression returns the probability of our observation being positive, True, or “Yes”. We call this class 1 and its notation is $P(class=1)$.\n",
    "\n",
    "As the probability gets closer to 1, our model is more confident that the observation is in class 1.\n",
    "\n",
    "Given: the feature vector, weight matrix and bias\n",
    "1. Linear function: \n",
    "    $$ z = w\\cdot x + b $$\n",
    "2. Applying activation: \n",
    "    $$ P(class = 1) = a = \\hat y = S(z) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWrite code for predictions\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Write code for predictions\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 The Loss Function: Log Loss\n",
    "\n",
    "For a linear regression model you used the MSE Loss. However, the same can not be applied here. Why? There is a great math explanation in chapter 3 of Michael Neilson’s deep learning [book](http://neuralnetworksanddeeplearning.com/chap3.html), but for now I’ll simply say it’s because our prediction function is non-linear (due to sigmoid transform). Squaring this prediction as we do in MSE results in a non-convex function with many local minimums. If our cost function has many local minimums, gradient descent may not find the optimal global minimum.\n",
    "\n",
    "Instead of the MSE we will use a loss function called the Cross-Entropy Loss or the Log Loss (denoted by $\\mathcal{L}(\\hat y, y)$. Cross Entropy loss can be divided into two separate loss functions: one for y = 1, and other for y = 0.\n",
    "\n",
    "1. if $y = 1$:\n",
    "$$ \\mathcal{L}(\\hat y, 1) = -\\log(\\hat y) $$ \n",
    "2. if $y = 0$:\n",
    "$$ \\mathcal{L}(\\hat y, 0) = -\\log(1 - \\hat y) $$ \n",
    "\n",
    "The benefits of taking the logarithm reveal themselves when you look at the loss function graphs for $y=1$ and $y=0$. These smooth monotonic functions (always increasing or always decreasing) make it easy to calculate the gradient and minimize cost. \n",
    "\n",
    "TODO: Insert Graphic\n",
    "\n",
    "These expressions can be combined to give:\n",
    "\n",
    "$$ \\mathcal{L} (\\hat y, y) = -[y\\log(\\hat y) + (1 - y)\\log(1 - \\hat y)] $$\n",
    "\n",
    "> Exercise: Prove this is true\n",
    "\n",
    "> Loss function and Cost function are almost synonymous, with a small caveat that we will get to later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Gradient Descent\n",
    "\n",
    "To minimize our cost, we use Gradient Descent just like before in Linear Regression. \n",
    "\n",
    "> There are other more sophisticated optimization algorithms out there such as Momentum, or RMSProp or ADAM, but you don’t have to worry about these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 1 Introduction - Stochastic Gradient Descent\n",
    "\n",
    "Gradient descent is an optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters (coefficients, or weights and bias) of our model.\n",
    "\n",
    "> Note: Stochastic Gradient Descent refers to using the gradient Descent algorithm on one training example at a time, contrasted to iterating over small batches, or the enitre training data at once\n",
    "\n",
    "Consider the 3-dimensional graph below in the context of a cost function. Our goal is to move from the mountain in the top right corner (high cost) to the dark blue sea in the bottom left (low cost). The arrows represent the direction of steepest descent (negative gradient) from any given point–the direction that decreases the cost function as quickly as possible.\n",
    "\n",
    "<img src=\"https://ml-cheatsheet.readthedocs.io/en/latest/_images/gradient_descent.png\">\n",
    "\n",
    "Starting at the top of the mountain, we take our first step downhill in the direction specified by the negative gradient. Next we recalculate the negative gradient (passing in the coordinates of our new point) and take another step in the direction it specifies. We continue this process iteratively until we get to the bottom of our graph, or to a point where we can no longer move downhill–a local minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 2 Learning Rate\n",
    "\n",
    "The size of these steps is called the learning rate. \n",
    "\n",
    "1. With a high learning rate we can cover more ground each step, but we risk overshooting the lowest point since the slope of the hill is constantly changing. \n",
    "2. With a low learning rate, we can confidently move in the direction of the negative gradient since we are recalculating it so frequently. \n",
    "\n",
    "> A very low learning rate is more precise, but calculating the gradient is time-consuming, so it will take us a very long time to get to the bottom.\n",
    "\n",
    "> A low learning rate might also get stuck in a local minima, as it is also a point of 0 gradient.\n",
    "\n",
    "> This is why we used a log loss. It has only a gloabal minimum, and not local Minima where we can get stuck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 3 Mathematics\n",
    "\n",
    "The Loss Functions tells us “how good” our model is at making predictions for a given set of parameters. The cost function has its own curve and its own gradients. The slope of this curve tells us how to update our parameters to make the model more accurate.\n",
    "\n",
    "There are two parameters in our cost function we can control: $w$ (weight) and $b$ (bias). Since we need to consider the impact each one has on the final prediction, we need to use partial derivatives. We calculate the partial derivatives of the cost function with respect to each parameter and store the results in a gradient.\n",
    "\n",
    "We have the following equations:\n",
    "\n",
    "1. $ z = w \\cdot x + b $\n",
    "2. $ \\hat y = S(z) $\n",
    "3. $ \\mathcal{L} (\\hat y, y) = -[y\\log(\\hat y) + (1 - y)\\log(1 - \\hat y)] $\n",
    "\n",
    "and what we need to compute \n",
    "$$ \\frac{\\partial \\mathcal{L}}{\\partial w}, \\frac{\\partial \\mathcal{L}}{\\partial b} $$\n",
    "\n",
    "And for this we will use the chain rule as follows:\n",
    "\n",
    "$$ \\implies \\frac{\\partial \\mathcal{L}}{\\partial w} = \\frac{d\\mathcal{L}}{d\\hat y} \\cdot \\frac{d \\hat y}{dz} \\cdot \\frac{\\partial z}{\\partial w} $$\n",
    "\n",
    "and\n",
    "\n",
    "$$ \\implies \\frac{\\partial \\mathcal{L}}{\\partial w} = \\frac{d\\mathcal{L}}{d\\hat y} \\cdot \\frac{d \\hat y}{dz} \\cdot \\frac{\\partial z}{\\partial w} $$\n",
    "\n",
    "> Solve these on your own and get to the requires solution. It might be tricky, but the concept from  MATH F111 and MATH F112 should help\n",
    "\n",
    "> Hint 1: The derivative o the sigmoid function is given by:\n",
    "$$ \\frac{dS(z)}{dz} = S(z)(s - S(z)) $$\n",
    "Hint 2: \n",
    "For reasons you will soon see, the shape of $ \\frac{\\partial \\mathcal{L}}{\\partial w}$ and $ w $ must be equal. Similarly for $b$\n",
    "\n",
    "The Final solution for these equations has the following structure:\n",
    "\n",
    "$$ \\implies \\frac{\\partial \\mathcal{L}}{\\partial w} = (\\hat y - y) \\cdot x^T $$\n",
    "\n",
    "$$ \\implies \\frac{\\partial \\mathcal{L}}{\\partial b} = (\\hat y - y) $$\n",
    "\n",
    "Now, we must update our parameters $ w $ and $b$.\n",
    "For this we use the gradient descent Optimizer. The algorithm for this is: \n",
    "\n",
    "$$ w := w - \\alpha \\frac{\\partial \\mathcal{L}}{\\partial w} $$\n",
    "\n",
    "\n",
    "$$ b := b - \\alpha \\frac{\\partial \\mathcal{L}}{\\partial b} $$\n",
    "\n",
    "This process must be repeat thousands of time, before we can reach the minima. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
